{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba1190f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from efficientdet_arch.efficientdet.dataset import CocoDataset, Resizer, Normalizer, Augmenter, collater\n",
    "from efficientdet_arch.backbone import EfficientDetBackbone\n",
    "from efficientdet_arch.efficientdet.utils import BBoxTransform, ClipBoxes\n",
    "from efficientdet_arch.utils.utils import preprocess, postprocess, invert_affine, display\n",
    "from helper import *  # including config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2e02562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abe45c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = [512, 640, 768, 896, 1024, 1280, 1280, 1536, 1536]\n",
    "\n",
    "PROJECT_NAME = \"goodbadchili\"\n",
    "EFFICIENTNET_COMPOUND_COEF = 0\n",
    "BATCH_SIZE = 32\n",
    "EPOCH_NUM = 5\n",
    "LEARNING_RATE = 1e-4\n",
    "OPTIMIZER = \"AdamW\"\n",
    "WEIGHT_PATH = \"weights/d0-chili.pth\"\n",
    "ANCHOR_RATIOS=[(1.0, 0.7), (1.0, 1.0), (1.0, 1.5)]\n",
    "ANCHOR_SCALES=[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "497838f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = os.path.join(os.path.abspath(os.getcwd()), \"datasets\", PROJECT_NAME)\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97a2162b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\fabia\\\\github\\\\efficientdet-mds1\\\\dataset\\\\data\\\\goodbadchili\\\\annotations\\\\instances_train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_95584/889059567.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m train_loader = DataLoader(\n\u001b[1;32m----> 2\u001b[1;33m     CocoDataset(\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mroot_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPROJECT_DATASET_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         transform=transforms.Compose([\n\u001b[0;32m      5\u001b[0m             \u001b[0mNormalizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"mean\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"std\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\github\\efficientdet-mds1\\efficientdet_arch\\efficientdet\\dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root_dir, set, transform)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoco\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'annotations'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'instances_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetImgIds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.python_env\\ml-env\\lib\\site-packages\\pycocotools\\coco.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, annotation_file)\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loading annotations into memory...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mtic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotation_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m                 \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'annotation file format {} not supported'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\fabia\\\\github\\\\efficientdet-mds1\\\\dataset\\\\data\\\\goodbadchili\\\\annotations\\\\instances_train.json'"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    CocoDataset(\n",
    "        root_dir=DATASET_DIR, set=\"train\",\n",
    "        transform=transforms.Compose([\n",
    "            Normalizer(mean=CONFIG[\"mean\"], std=CONFIG[\"std\"]),\n",
    "            Augmenter(),\n",
    "            Resizer(INPUT_DIM[EFFICIENTNET_COMPOUND_COEF])\n",
    "        ])\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, collate_fn=collater\n",
    ")\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf32b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientDetBackbone(num_classes=2, compound_coef=0, ratios=ANCHOR_RATIOS, scales=ANCHOR_SCALES)\n",
    "try:\n",
    "    missing_keys, unexpected_keys = model.load_state_dict(torch.load(\"efficientdet-d0.pth\"), strict=False)\n",
    "except Exception as e:\n",
    "    print(e, \"(Omit)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5e9945",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.apply(freeze_backbone)\n",
    "model = ModelWrapper(model, debug=False)\n",
    "model.to(DEVICE)\n",
    "model.train()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef123967",
   "metadata": {},
   "outputs": [],
   "source": [
    "if OPTIMIZER == \"AdamW\":\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), LEARNING_RATE)\n",
    "elif OPTIMIZER == \"SGD\":\n",
    "    optimizer = torch.optim.SGD(model.parameters(), LEARNING_RATE, momentum=0.9, nesterov=True)\n",
    "else:\n",
    "    raise Exception(\"Wrong Optimizer Option\")\n",
    "    \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550c99a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCH_NUM):\n",
    "    epoch_loss = []\n",
    "    progress_bar = tqdm(train_loader)\n",
    "    for i, data in enumerate(progress_bar):\n",
    "        try:\n",
    "            imgs, annot = data['img'], data['annot']\n",
    "            imgs, annot = imgs.to(DEVICE), annot.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            cls_loss, reg_loss = model(imgs, annot, obj_list=[\"good_chili\", \"bad_chili\"])\n",
    "            cls_loss, reg_loss = cls_loss.mean(), reg_loss.mean()\n",
    "            loss = cls_loss + reg_loss\n",
    "\n",
    "            if loss == 0 or not torch.isfinite(loss):\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss.append(float(loss))\n",
    "            progress_bar.set_description(\n",
    "                f\"\"\"Epoch: {epoch}/{EPOCH_NUM} | Iteration: {i+1}/{len(train_loader)} | Cls loss: {cls_loss.item():.5f} | Reg loss: {reg_loss.item():.5f} | Total loss: {loss.item():.5f}\"\"\"\n",
    "            )\n",
    "        except ValueError as e:\n",
    "            print(f\"[Error] {e}\")\n",
    "    scheduler.step(np.mean(epoch_loss))\n",
    "\n",
    "torch.save(model.model.state_dict(), WEIGHT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1575b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, len(epoch_loss)+1)\n",
    "\n",
    "plt.title('Loss vs Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(epochs, epoch_loss)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyml",
   "language": "python",
   "name": "pyml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
